{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción Estructural de Proteínas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Esta red intenta predecir  la estructura secundaria de una proteína  a partir de su secuencia  de aminoácidos, busca encontrar patrones asociados  a orientaciones tridimiencionales definidas dadas por los cuaterniones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de datos debe estar compuesta por  la diferencia de cuaterniones (la primera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = open(\"dataset2train\",\"r\") \n",
    "proteins = database.readlines()\n",
    "database.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "shuffle(proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de proteínas:  3275\n",
      "Proteinas en test:  1310\n",
      "Proteinas en train:  1965\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de proteínas: \",len(proteins))\n",
    "\n",
    "lim = int(len(proteins)*0.4)\n",
    "print(\"Proteinas en test: \",lim)\n",
    "print(\"Proteinas en train: \",len(proteins)-lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 15\n",
    "step = 3\n",
    "sequences_before_train = []\n",
    "sequences_after_train = []\n",
    "residues_train = []\n",
    "next_chars_train = []\n",
    "quaternions_before_train = []\n",
    "quaternions_after_train = []\n",
    "\n",
    "\n",
    "for protein in proteins[lim:]:\n",
    "  \n",
    "    nres = int((len(protein.split())+4)/5)\n",
    "    sequence = protein.split()[0:nres]\n",
    "    quaternion = protein.split()[nres:]\n",
    "\n",
    "    \n",
    "    for i in range(0, len(sequence) - maxlen + 1, step):\n",
    "       \n",
    "        sequences_before_train.append(sequence[i: i + int(maxlen/2)])\n",
    "        sequences_after_train.append(sequence[i + int(maxlen/2)+1: i + maxlen])\n",
    "        quat_before_train = quaternion[4*i: 4*(i - 1) + 4*int(maxlen/2)]\n",
    "        quat_after_train = quaternion[4*(i - 1) + 4*int(maxlen/2+1): 4*(i - 2) + 4*(maxlen)]\n",
    "        \n",
    "        quaternions_before_train.append(quat_before_train)\n",
    "        quaternions_after_train.append(quat_after_train)\n",
    "\n",
    "        residues_train.append(sequence[i + int(maxlen/2)])\n",
    "\n",
    "        next_chars_train.append(quaternion[4*(i - 1) + 4*int(maxlen/2):4*(i - 1) + 4*int(maxlen/2+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_to_take = int(maxlen/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 15\n",
    "step = 3\n",
    "sequences_before_test = []\n",
    "sequences_after_test = []\n",
    "residues_test = []\n",
    "next_chars_test = []\n",
    "quaternions_before_test = []\n",
    "quaternions_after_test = []\n",
    "\n",
    "for protein in proteins[0:lim]:\n",
    "    nres = int((len(protein.split())+4)/5)\n",
    "    sequence = protein.split()[0:nres]\n",
    "    quaternion = protein.split()[nres:]\n",
    "\n",
    "    for i in range(0, len(sequence) - maxlen + 1, step):\n",
    "        sequences_before_test.append(sequence[i: i + int(maxlen/2)])\n",
    "        sequences_after_test.append(sequence[i + int(maxlen/2)+1: i + maxlen])\n",
    "        quat_before_test = quaternion[4*i: 4*(i - 1) + 4*int(maxlen/2)]\n",
    "        quat_after_test = quaternion[4*(i - 1) + 4*int(maxlen/2+1): 4*(i - 2) + 4*(maxlen)]\n",
    "\n",
    "        quaternions_before_test.append(quat_before_test)\n",
    "        quaternions_after_test.append(quat_after_test)\n",
    "\n",
    "        residues_test.append(sequence[i + int(maxlen/2)])\n",
    "        \n",
    "        next_chars_test.append(quaternion[4*(i - 1) + 4*int(maxlen/2):4*(i - 1) + 4*int(maxlen/2+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for  sublist in l for item in sublist]\n",
    "flatten_sbta = flatten(sequences_before_train)\n",
    "flatten_sata = flatten(sequences_after_train)\n",
    "flatten_sbte = flatten(sequences_before_test)\n",
    "flatten_sate = flatten(sequences_after_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 168572\n",
      "Unique characters: 20\n",
      "['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE', 'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL']\n"
     ]
    }
   ],
   "source": [
    "print('Number of sequences:', len(sequences_before_test+sequences_after_test))\n",
    "chars = sorted(list(set(flatten_sbta + flatten_sata + flatten_sbte + flatten_sate)))\n",
    "print('Unique characters:', len(chars))\n",
    "print(chars)\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x_sequences_before_train = np.zeros((len(sequences_before_train), int(maxlen/2), len(chars)))\n",
    "x_sequences_after_train = np.zeros((len(sequences_after_train), int(maxlen/2), len(chars)))\n",
    "x_residues_train = np.zeros((len(sequences_before_train), 1, len(chars)))\n",
    "x_quaternions_before_train = np.zeros((len(sequences_before_train), int(maxlen/2)-1, 4))\n",
    "x_quaternions_after_train = np.zeros((len(sequences_after_train), int(maxlen/2)-1, 4))\n",
    "y_train = np.zeros((len(sequences_before_train), 4))\n",
    "\n",
    "for i, sequence in enumerate(sequences_before_train):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x_sequences_before_train[i, t, char_indices[char]] = 1\n",
    "        if(t < len(sequence) - 2):   \n",
    "            \n",
    "            x_quaternions_before_train[i, t, 0] = quaternions_before_train[i][4*t]\n",
    "            x_quaternions_before_train[i, t, 1] = quaternions_before_train[i][4*t+1]\n",
    "            x_quaternions_before_train[i, t, 2] = quaternions_before_train[i][4*t+2]\n",
    "            x_quaternions_before_train[i, t, 3] = quaternions_before_train[i][4*t+3]\n",
    "\n",
    "for i, sequence in enumerate(sequences_after_train):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x_sequences_after_train[i, t, char_indices[char]] = 1\n",
    "        if(t < len(sequence) - 2):\n",
    "            x_quaternions_after_train[i, t, 0] = quaternions_after_train[i][4*t]\n",
    "            x_quaternions_after_train[i, t, 1] = quaternions_after_train[i][4*t+1]\n",
    "            x_quaternions_after_train[i, t, 2] = quaternions_after_train[i][4*t+2]\n",
    "            x_quaternions_after_train[i, t, 3] = quaternions_after_train[i][4*t+3]\n",
    "        \n",
    "    x_residues_train[i, 0, char_indices[residues_train[i]]] = 1        \n",
    "    y_train[i, 0] = next_chars_train[i][0]\n",
    "    y_train[i, 1] = next_chars_train[i][1]\n",
    "    y_train[i, 2] = next_chars_train[i][2]\n",
    "    y_train[i, 3] = next_chars_train[i][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122981, 7, 20)\n"
     ]
    }
   ],
   "source": [
    "print(x_sequences_before_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x_sequences_before_test = np.zeros((len(sequences_before_test), int(maxlen/2), len(chars)))\n",
    "x_sequences_after_test = np.zeros((len(sequences_after_test), int(maxlen/2), len(chars)))\n",
    "x_residues_test = np.zeros((len(sequences_before_test), 1, len(chars)))\n",
    "x_quaternions_before_test = np.zeros((len(sequences_before_test), int(maxlen/2)-1, 4))\n",
    "x_quaternions_after_test = np.zeros((len(sequences_after_test), int(maxlen/2)-1, 4))\n",
    "y_test = np.zeros((len(sequences_before_test), 4))\n",
    "\n",
    "for i, sequence in enumerate(sequences_before_test):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x_sequences_before_test[i, t, char_indices[char]] = 1\n",
    "        if(t < len(sequence) - 2):\n",
    "            x_quaternions_before_test[i, t, 0] = quaternions_before_test[i][4*t]\n",
    "            x_quaternions_before_test[i, t, 1] = quaternions_before_test[i][4*t+1]\n",
    "            x_quaternions_before_test[i, t, 2] = quaternions_before_test[i][4*t+2]\n",
    "            x_quaternions_before_test[i, t, 3] = quaternions_before_test[i][4*t+3]\n",
    "\n",
    "for i, sequence in enumerate(sequences_after_test):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x_sequences_after_test[i, t, char_indices[char]] = 1\n",
    "        if(t < len(sequence) - 2):\n",
    "            x_quaternions_after_test[i, t, 0] = quaternions_after_test[i][4*t]\n",
    "            x_quaternions_after_test[i, t, 1] = quaternions_after_test[i][4*t+1]\n",
    "            x_quaternions_after_test[i, t, 2] = quaternions_after_test[i][4*t+2]\n",
    "            x_quaternions_after_test[i, t, 3] = quaternions_after_test[i][4*t+3]\n",
    "        \n",
    "    x_residues_test[i, 0, char_indices[residues_test[i]]] = 1        \n",
    "    y_test[i, 0] = next_chars_test[i][0]\n",
    "    y_test[i, 1] = next_chars_test[i][1]\n",
    "    y_test[i, 2] = next_chars_test[i][2]\n",
    "    y_test[i, 3] = next_chars_test[i][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0130 16:50:54.306049 140378957707072 deprecation_wrapper.py:119] From /home/nef/miniconda3/envs/my_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0130 16:50:54.498802 140378957707072 deprecation_wrapper.py:119] From /home/nef/miniconda3/envs/my_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0130 16:50:54.533192 140378957707072 deprecation_wrapper.py:119] From /home/nef/miniconda3/envs/my_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0130 16:50:55.212398 140378957707072 deprecation_wrapper.py:119] From /home/nef/miniconda3/envs/my_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0130 16:50:55.221877 140378957707072 deprecation.py:506] From /home/nef/miniconda3/envs/my_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "from keras import Input, layers\n",
    "\n",
    "input_sequences_before = Input(shape=(int(maxlen/2), len(chars)))\n",
    "sequences_layers_before = layers.SimpleRNN(128,return_sequences=True,activation='relu')(input_sequences_before)\n",
    "sequences_layers_before = layers.SimpleRNN(128,return_sequences=True,activation='relu')(sequences_layers_before)\n",
    "sequences_layers_before = layers.SimpleRNN(128,activation='relu')(sequences_layers_before)\n",
    "sequences_layers_before = layers.Dense(128,activation='relu')(sequences_layers_before)\n",
    "sequences_layers_before = layers.Dropout(0.3)(sequences_layers_before)\n",
    "sequences_layers_before = layers.Dense(128,activation='relu')(sequences_layers_before)\n",
    "#output = layers.Dense(4, activation='linear')(sequences_layers_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 20\n"
     ]
    }
   ],
   "source": [
    "print(int(maxlen/2), len(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "input_sequences_after = Input(shape=(int(maxlen/2), len(chars)))\n",
    "sequences_layers_after = layers.SimpleRNN(250,return_sequences=True,activation='relu')(input_sequences_after)\n",
    "sequences_layers_after = layers.SimpleRNN(250,return_sequences=True,activation='relu')(sequences_layers_after)\n",
    "sequences_layers_after = layers.SimpleRNN(250,activation='relu')(sequences_layers_after)\n",
    "sequences_layers_after = layers.Dense(250,activation='relu')(sequences_layers_after)\n",
    "sequences_layers_after = layers.Dense(250,activation='relu')(sequences_layers_after)\n",
    "sequences_layers_after = layers.Dropout(0.001)(sequences_layers_after)\n",
    "sequences_layers_after = layers.Dense(250,activation='relu')(sequences_layers_after)\n",
    "#sequences_layers_after = layers.Dense(250,activation='relu')(sequences_layers_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "input_residues = Input(shape=(1, len(chars)))\n",
    "residues_layers = layers.SimpleRNN(250,return_sequences=True,activation='relu')(input_residues)\n",
    "residues_layers = layers.SimpleRNN(250,return_sequences=True,activation='relu')(residues_layers)\n",
    "residues_layers = layers.SimpleRNN(250,activation='relu')(residues_layers)\n",
    "residues_layers = layers.Dense(250,activation='relu')(residues_layers)\n",
    "residues_layers = layers.Dense(250,activation='relu')(residues_layers)\n",
    "residues_layers = layers.Dropout(0.001)(residues_layers)\n",
    "residues_layers = layers.Dense(250,activation='relu')(residues_layers)\n",
    "#residues_layers = layers.Dense(250,activation='relu')(residues_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_quaternions_before = Input(shape=(int(maxlen/2-1), 4))\n",
    "quaternions_layers_before = layers.SimpleRNN(250,return_sequences=True,activation='relu')(input_quaternions_before)\n",
    "quaternions_layers_before = layers.SimpleRNN(250,return_sequences=True,activation='relu')(quaternions_layers_before)\n",
    "quaternions_layers_before = layers.SimpleRNN(250,activation='relu')(quaternions_layers_before)#quaternions_layers_before = layers.Dense(250,activation='relu')(quaternions_layers_before)\n",
    "quaternions_layers_before = layers.Dense(250,activation='relu')(quaternions_layers_before)\n",
    "quaternions_layers_before = layers.Dropout(0.001)(quaternions_layers_before)\n",
    "quaternions_layers_before = layers.Dense(250,activation='relu')(quaternions_layers_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 20\n"
     ]
    }
   ],
   "source": [
    "print(1, len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.216666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "313/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "concatenated = layers.concatenate([sequences_layers_before, sequences_layers_after, residues_layers,quaternions_layers_before],axis = -1)\n",
    "concatenated = layers.Dense(2000, activation='relu')(concatenated)\n",
    "concatenated = layers.Dense(1000, activation='relu')(concatenated)\n",
    "concatenated = layers.Dense(600, activation='relu')(concatenated)\n",
    "concatenated = layers.Dense(500, activation='relu')(concatenated)\n",
    "concatenated = layers.Dense(400, activation='relu')(concatenated)\n",
    "concatenated = layers.Dropout(0.001)(concatenated)\n",
    "concatenated = layers.Dense(300, activation='relu')(concatenated)\n",
    "concatenated = layers.Dense(250, activation='relu')(concatenated)\n",
    "output = layers.Dense(4, activation='linear')(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = Model([input_sequences_before,input_sequences_after,input_residues,input_quaternions_before],output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0130 16:50:57.025796 140378957707072 deprecation_wrapper.py:119] From /home/nef/miniconda3/envs/my_project/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mae', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0130 16:50:58.857059 140378957707072 deprecation_wrapper.py:119] From /home/nef/miniconda3/envs/my_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122981 samples, validate on 84286 samples\n",
      "Epoch 1/65\n",
      "122981/122981 [==============================] - 299s 2ms/step - loss: 0.3244 - val_loss: 0.3096\n",
      "Epoch 2/65\n",
      "122981/122981 [==============================] - 285s 2ms/step - loss: 0.3084 - val_loss: 0.3033\n",
      "Epoch 3/65\n",
      "122981/122981 [==============================] - 286s 2ms/step - loss: 0.3033 - val_loss: 0.2958\n",
      "Epoch 4/65\n",
      "122981/122981 [==============================] - 286s 2ms/step - loss: 0.2920 - val_loss: 0.2884\n",
      "Epoch 5/65\n",
      "122981/122981 [==============================] - 297s 2ms/step - loss: 0.2871 - val_loss: 0.2854\n",
      "Epoch 6/65\n",
      "122981/122981 [==============================] - 298s 2ms/step - loss: 0.2829 - val_loss: 0.2832\n",
      "Epoch 7/65\n",
      "122981/122981 [==============================] - 298s 2ms/step - loss: 0.2784 - val_loss: 0.2778\n",
      "Epoch 8/65\n",
      "122981/122981 [==============================] - 300s 2ms/step - loss: 0.2752 - val_loss: 0.2768\n",
      "Epoch 9/65\n",
      "122981/122981 [==============================] - 299s 2ms/step - loss: 0.2722 - val_loss: 0.2772\n",
      "Epoch 10/65\n",
      "122981/122981 [==============================] - 300s 2ms/step - loss: 0.2703 - val_loss: 0.2746\n",
      "Epoch 11/65\n",
      "122981/122981 [==============================] - 300s 2ms/step - loss: 0.2680 - val_loss: 0.2767\n",
      "Epoch 12/65\n",
      "122981/122981 [==============================] - 301s 2ms/step - loss: 0.2660 - val_loss: 0.2743\n",
      "Epoch 13/65\n",
      "122981/122981 [==============================] - 301s 2ms/step - loss: 0.2641 - val_loss: 0.2742\n",
      "Epoch 14/65\n",
      "122981/122981 [==============================] - 303s 2ms/step - loss: 0.2623 - val_loss: 0.2727\n",
      "Epoch 15/65\n",
      "122981/122981 [==============================] - 302s 2ms/step - loss: 0.2613 - val_loss: 0.2724\n",
      "Epoch 16/65\n",
      "122981/122981 [==============================] - 303s 2ms/step - loss: 0.2595 - val_loss: 0.2724\n",
      "Epoch 17/65\n",
      "122981/122981 [==============================] - 304s 2ms/step - loss: 0.2578 - val_loss: 0.2725\n",
      "Epoch 18/65\n",
      "122981/122981 [==============================] - 304s 2ms/step - loss: 0.2562 - val_loss: 0.2719\n",
      "Epoch 19/65\n",
      "122981/122981 [==============================] - 305s 2ms/step - loss: 0.2551 - val_loss: 0.2738\n",
      "Epoch 20/65\n",
      "122981/122981 [==============================] - 306s 2ms/step - loss: 0.2536 - val_loss: 0.2734\n",
      "Epoch 21/65\n",
      "122981/122981 [==============================] - 306s 2ms/step - loss: 0.2525 - val_loss: 0.2722\n",
      "Epoch 22/65\n",
      "103900/122981 [========================>.....] - ETA: 40s - loss: 0.2513"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_sequences_before_train,x_sequences_after_train,x_residues_train,x_quaternions_before_train], y_train, validation_data=([x_sequences_before_test,x_sequences_after_test,x_residues_test,x_quaternions_before_test],y_test), batch_size=100, epochs=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('fifty_epochs.h5') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "\n",
    "\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "print(history.history.keys())\n",
    "plt.plot( history.history['loss'],label='Train')\n",
    "plt.plot(history.history['val_loss'],label='Test')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('mae')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('learning_curve_original.png', dpi=400)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([x_sequences_before_test,x_sequences_after_test,x_residues_test,x_quaternions_before_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos que  tan buena es la red "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for i in range(5):\n",
    "    print(\"Original: \",y_test[i],\" Prediccion: \",predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrr as pyrr\n",
    "import math as mt\n",
    "import numpy as np\n",
    "\n",
    "database = open(\"validation_set.txt\",\"r\") \n",
    "proteins_2predict = database.readlines()\n",
    "database.close()\n",
    "proteins_2predict = proteins_2predict[:] #ojo aqui\n",
    "\n",
    "dataset = open(\"validation_keys\",\"r\") \n",
    "claves_2predict = dataset.readlines()\n",
    "dataset.close()\n",
    "\n",
    "\n",
    "for line  in claves_2predict:\n",
    "    keys = line.split(\", \")\n",
    "    b = keys[len(keys)-1].rstrip('\\n')\n",
    "    keys[len(keys)-1] = b\n",
    "    keys = keys[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys[85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins_2predict.pop(85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins_2predict.pop(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins_2predict.pop(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins_2predict.pop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(proteins_2predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from angles import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Ramachandran_straightness(Psi,Phi):\n",
    "      \n",
    "    theta= []\n",
    "    i=1\n",
    "    while i < len (Psi):\n",
    "        angle=(Phi[i+1] + Psi[i] - Phi[i] - Psi[i-1])\n",
    "        theta.append(normalize(angle, -180, 180))\n",
    "        if i == (len(Psi)-2):\n",
    "            break\n",
    "        else:\n",
    "            i=i+1\n",
    "           \n",
    "    s_ramachandran = []\n",
    "    for i in range(len(theta)):\n",
    "        s = 1-(abs(theta[i])/180)\n",
    "        s_ramachandran.append(s)\n",
    "    \n",
    "    return s_ramachandran  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_quaternions_straightness(x): #La  función toma las predicciones normalizadas de los quaterniones\n",
    "    s_quaternions_diff_jmol=[]       #\n",
    "    \n",
    "    for i in range(len(x)-1):\n",
    "        dot= pyrr.quaternion.dot(x[i+1], x[i])\n",
    "        if dot>1:\n",
    "            dot=1\n",
    "        else:\n",
    "            s = 1- (mt.acos(abs(dot))/(mt.pi/2))\n",
    "   \n",
    "            s_quaternions_diff_jmol.append(s)\n",
    "        \n",
    "    return s_quaternions_diff_jmol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, protein in enumerate(proteins_2predict):\n",
    "\n",
    "\n",
    "    print(\"Proteina:\",keys[index], \"indice\", index)\n",
    "    maxlen = 15\n",
    "    step = 1\n",
    "\n",
    "    sequences_before_validation = []\n",
    "    sequences_after_validation = []\n",
    "    residues_validation = []\n",
    "    quaternions_before_validation = []\n",
    "\n",
    "\n",
    "    nres_val = int((len(protein.split())+4)/5)\n",
    "    sequence_val = protein.split()[0:nres_val]\n",
    "    quaternion = protein.split()[nres_val:]\n",
    "\n",
    "    for i in range(0, len(sequence_val) - maxlen + 1, step):\n",
    "        sequences_before_validation.append(sequence_val[i: i + int(maxlen/2)])    \n",
    "        sequences_after_validation.append(sequence_val[i + int(maxlen/2)+1: i + maxlen])\n",
    "        residues_validation.append(sequence_val[i + int(maxlen/2)])\n",
    "        quat_before_v = quaternion[4*i: 4*(i - 1) + 4*int(maxlen/2)]\n",
    "        quaternions_before_validation.append(quat_before_v)\n",
    "    \n",
    "    \n",
    "    aa_2predict = sequence_val[7:len(sequence_val)-7]\n",
    "    #a = \"aa_2predict_of\"\n",
    "    #b = keys[index]\n",
    "    #aa_2predict = open(a+b, \"w\")\n",
    "    #aa_2predict.write(str(sequence_val[7:len(sequence_val)-7]))\n",
    "    #aa_2predict.close\n",
    "        \n",
    "    print('Vectorization...')\n",
    "    x_sequences_before_validation = np.zeros((len(sequences_before_validation), int(maxlen/2), len(chars)))\n",
    "    x_sequences_after_validation = np.zeros((len(sequences_after_test), int(maxlen/2), len(chars)))\n",
    "    x_residues_validation = np.zeros((len(sequences_before_validation), 1, len(chars)))\n",
    "    x_quaternions_before_validation = np.zeros((len(sequences_before_validation), int(maxlen/2)-1, 4))\n",
    "    y_test_validation = np.zeros((len(sequences_before_validation), 4))\n",
    "    \n",
    "#_________________________________________________________________________________________________________\n",
    "\n",
    "    for i, sequence in enumerate(sequences_before_validation):\n",
    "        for t, char in enumerate(sequence):\n",
    "            x_sequences_before_validation[i, t, char_indices[char]] = 1\n",
    "            if(t < len(sequence) - 2):\n",
    "                x_quaternions_before_validation[i, t, 0] = quaternions_before_validation[i][4*t]\n",
    "                x_quaternions_before_validation[i, t, 1] = quaternions_before_validation[i][4*t+1]\n",
    "                x_quaternions_before_validation[i, t, 2] = quaternions_before_validation[i][4*t+2]\n",
    "                x_quaternions_before_validation[i, t, 3] = quaternions_before_validation[i][4*t+3]\n",
    "\n",
    "        \n",
    "        x_residues_validation[i, 0, char_indices[residues_validation[i]]] = 1        \n",
    "        y_test_validation[i, 0] = next_chars_test[i][0]\n",
    "        y_test_validation[i, 1] = next_chars_test[i][1]\n",
    "        y_test_validation[i, 2] = next_chars_test[i][2]\n",
    "        y_test_validation[i, 3] = next_chars_test[i][3]\n",
    "    \n",
    "    print('Vectorization...')\n",
    "    x_sequences_before_validation = np.zeros((len(sequences_before_validation), int(maxlen/2), len(chars)))\n",
    "    x_sequences_after_validation = np.zeros((len(sequences_after_validation), int(maxlen/2), len(chars)))\n",
    "    x_residues_validation = np.zeros((len(sequences_before_validation), 1, len(chars)))\n",
    "    x_quaternions_before_validation = np.zeros((len(sequences_before_validation), int(maxlen/2)-1, 4))\n",
    "\n",
    "\n",
    "    for i, sequence in enumerate(sequences_before_validation):\n",
    "        for t, char in enumerate(sequence):\n",
    "            x_sequences_before_validation[i, t, char_indices[char]] = 1\n",
    "            if(t < len(sequence) - 2):\n",
    "                x_quaternions_before_validation[i, t, 0] = quaternions_before_validation[i][4*t]\n",
    "                x_quaternions_before_validation[i, t, 1] = quaternions_before_validation[i][4*t+1]\n",
    "                x_quaternions_before_validation[i, t, 2] = quaternions_before_validation[i][4*t+2]\n",
    "                x_quaternions_before_validation[i, t, 3] = quaternions_before_validation[i][4*t+3]\n",
    "\n",
    "    for i, sequence in enumerate(sequences_after_validation):\n",
    "        for t, char in enumerate(sequence):\n",
    "            x_sequences_after_validation[i, t, char_indices[char]] = 1        \n",
    "        x_residues_validation[i, 0, char_indices[residues_validation[i]]] = 1\n",
    "    \n",
    "#_____________________________________________________________________________________________________\n",
    "\n",
    "    print(\"generando las predicciones...\")   \n",
    "    predictions_validation = model.predict([x_sequences_before_validation,x_sequences_after_validation,x_residues_validation,x_quaternions_before_validation])\n",
    "#_____________________________________________________________________________________________________\n",
    "\n",
    "    print(\"Normalizando las predicciones...\")\n",
    "    pred_normalized=[]\n",
    "    for i in  range(len(predictions_validation)):\n",
    "        pred_normalized.append(pyrr.quaternion.normalise(predictions_validation[i]))\n",
    "        \n",
    "    predictions_normalized=[]\n",
    "    for j in range(len(pred_normalized)):\n",
    "        cuarteto=[]\n",
    "        cuarteto.append(pred_normalized[j][0])\n",
    "        cuarteto.append(pred_normalized[j][1])\n",
    "        cuarteto.append(pred_normalized[j][2])\n",
    "        cuarteto.append(pred_normalized[j][3])\n",
    "        predictions_normalized.append(cuarteto)\n",
    "        \n",
    "#______________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "    \n",
    "    key_lower = keys[index].lower()\n",
    "    print(key_lower, keys[index]) \n",
    "#________________________________________________________________________________________________________\n",
    "\n",
    "    from prody import *\n",
    "    from pylab import *\n",
    "    from pyrr import Quaternion, Matrix33, Matrix44, Vector3, Vector4\n",
    "    import py3Dmol\n",
    "\n",
    "    %matplotlib inline\n",
    "    confProDy(auto_show=False)\n",
    "    confProDy(auto_secondary=True)\n",
    "\n",
    "\n",
    "    p38 = parsePDB(key_lower)\n",
    "\n",
    "#______________________________________________________________________________________________________\n",
    "\n",
    "    print(\"generando el  straightness de Ramachandran para la cadena A\")\n",
    "          \n",
    "    #para la cadena A (arreglar para aceptar mas cadenas)      \n",
    "          \n",
    "    p38['A'].getSequence()          \n",
    "    chain = p38['A']\n",
    "    Phi = []; Psi = []; c = []\n",
    "    for res in chain.iterResidues():\n",
    "        try:\n",
    "            phi = calcPhi(res)\n",
    "            psi = calcPsi(res)\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            Phi.append(phi)\n",
    "            Psi.append(psi)\n",
    "            if res.getResname() == 'GLY':\n",
    "                c.append('r')\n",
    "            else:\n",
    "                c.append('b')   \n",
    "                \n",
    "#_________________________________________________________________________________________________________\n",
    "\n",
    "    amino_number= len(Psi)+2\n",
    "    amino_number\n",
    "#_____________________________________________________________________________________________________\n",
    "\n",
    "    ppsi = Psi[len_to_take-2:(amino_number-len_to_take)-1]\n",
    "    \n",
    "#_____________________________________________________________________________________________________\n",
    "\n",
    "    pphi = Phi[len_to_take-2:(amino_number-len_to_take)-1]\n",
    "    \n",
    "#_____________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "    ramachandran_straightness = get_Ramachandran_straightness(ppsi,pphi)\n",
    "    print(\"len(ramachandran_straightness)\", len(ramachandran_straightness))\n",
    "#____________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "    straightnes_quaternions = get_quaternions_straightness(predictions_normalized)\n",
    "    print(\"len(straightnes_quaternions)\", len(straightnes_quaternions))\n",
    "        \n",
    "#____________________________________________________________________________________________________\n",
    "\n",
    "    aa_2predict.pop()\n",
    "#____________________________________________________________________________________________________\n",
    "\n",
    "    print(\"No. de aminoácidos a predecir \", len( aa_2predict))\n",
    "    \n",
    "#____________________________________________________________________________________________________\n",
    "\n",
    "    import matplotlib.pyplot as plt \n",
    "    %matplotlib notebook\n",
    "    plt.plot(ramachandran_straightness, straightnes_quaternions, 'ro')\n",
    "    plt.axis([0, 1,0, 1])\n",
    "    plt.ylabel('Ramachandran-C-Based-Straightness')\n",
    "    plt.xlabel('quaternion-C-Based-Straightness')\n",
    "    extension = '.png'\n",
    "    plt.savefig(key_lower + extension, dpi=400)\n",
    "    \n",
    "    \n",
    "#_____________________________________________________________________________________________________\n",
    "\n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(ramachandran_straightness, straightnes_quaternions)\n",
    "\n",
    "#____________________________________________________________________________________________________\n",
    "\n",
    "    print (\"r-squared:\", r_value**2)\n",
    "    \n",
    "#_____________________________________________________________________________________________________\n",
    "\n",
    "    print(\"slop\", slope)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
